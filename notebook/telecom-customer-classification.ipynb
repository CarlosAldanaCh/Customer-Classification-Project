{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b2cdc7",
   "metadata": {},
   "source": [
    "# **Descripción del proyecto**\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes\n",
    "utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el\n",
    "comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline:\n",
    "Smart o Ultra.\n",
    "Para esta tarea de clasificación debo crear un modelo que escoja el plan correcto.\n",
    "Para entrenar mi modelo, utilizaré los datos de comportamiento del usuario\n",
    "del curso sobre Análisis estadísticos de datos. Como ya hice el paso de procesar los\n",
    "datos, puedo lanzarme directo a crear el modelo.\n",
    "Desarrollaré un modelo con la mayor exactitud posible. En este proyecto, debe superar el umbral de\n",
    "exactitud de 0.75.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ce53f",
   "metadata": {},
   "source": [
    "\n",
    "#  Flujo de trabajo del proyecto\n",
    "\n",
    "En este proyecto voy a construir y evaluar distintos modelos de **clasificación** para predecir si un cliente pertenece a la tarifa *Ultra o Smart* a partir de su uso de llamadas, minutos, mensajes y datos móviles.\n",
    "\n",
    "El flujo de trabajo que voy a seguir es el siguiente:\n",
    "\n",
    "1. **Importación de librerías**\n",
    "   Inicio cargando todas las herramientas necesarias: `pandas` para la manipulación de datos, módulos de `Scikit-Learn` para la construcción de modelos de clasificación y la evaluación de métricas y `joblib` para guardar el modelo final.\n",
    "\n",
    "2. **Carga y exploración de datos (EDA rápido)**\n",
    "   Importo el dataset y realizo una exploración inicial para verificar que los datos sean correctos: ausencia de valores nulos, tipos adecuados de variables y distribución general de las características.\n",
    "\n",
    "3. **Definición de variables**\n",
    "   Separo el dataset en:\n",
    "\n",
    "   * **Features (X):** `calls`, `minutes`, `messages`, `mb_used`.\n",
    "   * **Target (y):** `is_Ultra`.\n",
    "\n",
    "4. **División en entrenamiento y prueba (sin conjunto de validación ya que se utiliza GridSearchCV)**\n",
    "   Divido los datos en conjuntos de **entrenamiento** y **prueba**, manteniendo la proporción de clases para garantizar una evaluación justa.\n",
    "\n",
    "5. **Entrenamiento con GridSearchCV**\n",
    "   Utilizo la búsqueda de hiperparámetros con validación cruzada (`GridSearchCV`) para ajustar tres modelos distintos:\n",
    "\n",
    "   * **Decision Tree Classifier**\n",
    "   * **Random Forest Classifier**\n",
    "   * **Logistic Regression** (con escalado de features)\n",
    "\n",
    "6. **Selección del mejor modelo**\n",
    "   Identifico los mejores hiperparámetros para cada modelo y evalúo el rendimiento en el conjunto de prueba. Finalmente, selecciono el modelo con la mayor exactitud (*accuracy*) como el más adecuado para esta tarea y lo guardo por si se quiere utilizar más adelante.\n",
    "\n",
    "7. **Prueba de cordura**\n",
    "   Realizo una prueba de cordura para asegurarme de que el modelo seleccionado generaliza bien a datos no vistos. Esto implica comparar el modelo entrenado contra un modelo tonto (baseline) que no aprende nada de los datos.\n",
    "\n",
    "      - Si el modelo tiene un rendimiento similar o peor que el baseline → no está aprendiendo nada útil.\n",
    "\n",
    "      - Si el modelo supera claramente al baseline →  demuestra que sí captura patrones.\n",
    "\n",
    "8. **Conclusión**\n",
    "   Resumo los hallazgos clave, el rendimiento del modelo seleccionado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd95b04",
   "metadata": {},
   "source": [
    "## **Importación de librerías**\n",
    "   Inicio cargando todas las herramientas necesarias: `pandas` para la manipulación de datos, módulos de `Scikit-Learn` para la construcción de modelos de clasificación y la evaluación de métricas y `joblib` para guardar el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44579b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Librerías para modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "# Librerías para evaluación\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Librería para guardar el mejor modelo\n",
    "from joblib import dump, load\n",
    "# Establecer semilla para reproducibilidad\n",
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363450f2",
   "metadata": {},
   "source": [
    "## **Carga y exploración de datos (EDA rápido)**\n",
    "   Importo el dataset y realizo una exploración inicial para verificar que los datos sean correctos: ausencia de valores nulos, tipos adecuados de variables y distribución general de las características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b254643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv(r'..\\data\\users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c34b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pequeña exploración de los datos\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637719c",
   "metadata": {},
   "source": [
    "## **Definición de variables**\n",
    "   Separo el dataset en:\n",
    "\n",
    "   * **Features (X):** `calls`, `minutes`, `messages`, `mb_used`.\n",
    "   * **Target (y):** `is_Ultra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d1d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 3214, Target: 3214\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en features y target\n",
    "X = df.drop(columns=['is_ultra'])\n",
    "y = df['is_ultra']\n",
    "# Comprobar si tienen la misma longitud\n",
    "print(f'Features: {X.shape[0]}, Target: {y.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7e406",
   "metadata": {},
   "source": [
    "## **División en entrenamiento y prueba (sin conjunto de validación ya que se utiliza GridSearchCV)**\n",
    "   Divido los datos en conjuntos de **entrenamiento** y **prueba**, manteniendo la proporción de clases para garantizar una evaluación justa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c323fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2571, 4), X_test: (643, 4), y_train: (2571,), y_test: (643,)\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos para entrenamiento y prueba ya que trabajaré con gridsearch\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE)\n",
    "# Comprobar las dimensiones de los conjuntos\n",
    "print(f'X_train: {X_train.shape}, X_test: {X_test.shape}, y_train: {y_train.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdd7a18",
   "metadata": {},
   "source": [
    "## **Entrenamiento con GridSearchCV**\n",
    "   Utilizo la búsqueda de hiperparámetros con validación cruzada (`GridSearchCV`) para ajustar tres modelos distintos:\n",
    "\n",
    "   * **Decision Tree Classifier**\n",
    "   * **Random Forest Classifier**\n",
    "   * **Logistic Regression** (con escalado de features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea703b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar la validación cruzada estratificada con StratifiedKFold en 5 pliegues\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a4d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para Decision Tree: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 9, 'min_samples_split': 2}\n",
      "Mejor score de validación cruzada para Decision Tree: 0.802\n"
     ]
    }
   ],
   "source": [
    "# Empezaré con un Decision Tree\n",
    "# Definir el modelo\n",
    "tree_model = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "# Definir los hiperparámetros a probar\n",
    "tree_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(1, 11)),   \n",
    "    'min_samples_split': list(range(2, 11,2)),    \n",
    "    'min_samples_leaf': list(range(1, 11,2))      \n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_tree = GridSearchCV(estimator=tree_model, param_grid=tree_params, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_tree.fit(X_train, y_train)\n",
    "# Obtener el mejor modelo y mejores hiperparámetros\n",
    "best_tree = grid_tree.best_estimator_\n",
    "best_tree_params = grid_tree.best_params_\n",
    "print(f'Mejores hiperparámetros para Decision Tree: {best_tree_params}')\n",
    "print(f'Mejor score de validación cruzada para Decision Tree: {grid_tree.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2793793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba para Decision Tree: 0.782\n"
     ]
    }
   ],
   "source": [
    "# Probar el mejor modelo en el conjunto de prueba\n",
    "pred_tree = best_tree.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, pred_tree)\n",
    "print(f'Accuracy en el conjunto de prueba para Decision Tree: {accuracy_tree:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48282c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para Random Forest: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 30}\n",
      "Mejor score de validación cruzada para Random Forest: 0.817\n"
     ]
    }
   ],
   "source": [
    "# Continuamos con Random Forest\n",
    "# Definir el modelo\n",
    "forest_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "# Definir los hiperparámetros a probar\n",
    "forest_params = {\n",
    "    'n_estimators': list(range(10, 51, 10)),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(1, 11)),   \n",
    "    'min_samples_split':list(range(2,11,2)),   \n",
    "    'min_samples_leaf': list(range(1,8,2))   \n",
    "}\n",
    "# Configurar GridSearchCV\n",
    "grid_forest = GridSearchCV(estimator=forest_model, param_grid=forest_params, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_forest.fit(X_train, y_train)\n",
    "# Obtener el mejor modelo y mejores hiperparámetros\n",
    "best_forest = grid_forest.best_estimator_\n",
    "best_forest_params = grid_forest.best_params_\n",
    "print(f'Mejores hiperparámetros para Random Forest: {best_forest_params}')\n",
    "print(f'Mejor score de validación cruzada para Random Forest: {grid_forest.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "362f07c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba para Random Forest: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "pred_forest = best_forest.predict(X_test)\n",
    "accuracy_forest = accuracy_score(y_test, pred_forest)\n",
    "print(f'Accuracy en el conjunto de prueba para Random Forest: {accuracy_forest:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f61d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros para Regresión Logística: {'logistic__C': 0.1, 'logistic__penalty': 'l2', 'logistic__solver': 'liblinear'}\n",
      "Mejor score de validación cruzada para Regresión Logística: 0.748\n"
     ]
    }
   ],
   "source": [
    "# Por ultimo, probaré con Regresión Logística\n",
    "# Definir el modelo con un pipeline que incluya escalado ya que los modelos lineales lo requieren\n",
    "log_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logistic', LogisticRegression(random_state=RANDOM_STATE, max_iter=1000))\n",
    "])\n",
    "# Definir los hiperparámetros a probar\n",
    "param_grid_log = [\n",
    "    {   \n",
    "        \"logistic__solver\": [\"liblinear\"],\n",
    "        \"logistic__penalty\": [\"l1\", \"l2\"],\n",
    "        \"logistic__C\": [0.01, 0.1, 1, 10, 100]\n",
    "    }]\n",
    "# Configurar GridSearchCV\n",
    "grid_log = GridSearchCV(estimator=log_model, param_grid=param_grid_log, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "grid_log.fit(X_train, y_train)\n",
    "# Obtener el mejor modelo y mejores hiperparámetros\n",
    "best_log = grid_log.best_estimator_\n",
    "best_log_params = grid_log.best_params_\n",
    "print(f'Mejores hiperparámetros para Regresión Logística: {best_log_params}')\n",
    "print(f'Mejor score de validación cruzada para Regresión Logística: {grid_log.best_score_:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e09029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba para Regresión Logística: 0.757\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "pred_log = best_log.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, pred_log)\n",
    "print(f'Accuracy en el conjunto de prueba para Regresión Logística: {accuracy_log:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358f48d",
   "metadata": {},
   "source": [
    "## **Selección del mejor modelo**\n",
    "   Ahora que ya identifiqué los mejores hiperparámetros para cada modelo y evalué el rendimiento en el conjunto de prueba. Finalmente, selecciono el modelo con la mayor exactitud (*accuracy*) como el más adecuado para esta tarea y lo guardé por si se quiere utilizar más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcdf3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es Random Forest con exactitud: 79.47%\n"
     ]
    }
   ],
   "source": [
    "# Conclusión: El mejor modelo es el que tiene mayor accuracy en el conjunto de prueba\n",
    "best_model = None\n",
    "if accuracy_tree >= accuracy_forest and accuracy_tree >= accuracy_log:\n",
    "    best_model = best_tree\n",
    "    print(f\"El mejor modelo es Decision Tree con exactitud: {(accuracy_tree)*100:.2f}%\")\n",
    "elif accuracy_forest >= accuracy_tree and accuracy_forest >= accuracy_log:\n",
    "    best_model = best_forest\n",
    "    print(f\"El mejor modelo es Random Forest con exactitud: {(accuracy_forest)*100:.2f}%\")\n",
    "else:\n",
    "    best_model = best_log\n",
    "    print(f\"El mejor modelo es Regresión Logística con exactitud: {(accuracy_log)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099a95a",
   "metadata": {},
   "source": [
    "## Prueba de cordura\n",
    " Realizo una prueba de cordura para asegurarme de que el modelo seleccionado generaliza bien a datos no vistos. Esto implica comparar el modelo entrenado contra un modelo tonto (baseline) que no aprende nada de los datos.\n",
    "\n",
    "    - Si el modelo tiene un rendimiento similar o peor que el baseline → no está aprendiendo nada útil.\n",
    "\n",
    "    - Si el modelo supera claramente al baseline →  demuestra que sí captura patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "248ecb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo tonto (baseline) en el conjunto de prueba: 0.695\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo tonto (baseline)\n",
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "# Entrenar el modelo tonto con los datos de entrenamiento\n",
    "dummy_model.fit(X_train, y_train)\n",
    "# Predecir con el modelo tonto en el conjunto de prueba\n",
    "pred_dummy = dummy_model.predict(X_test)\n",
    "# Evaluar el modelo tonto en el conjunto de prueba\n",
    "accuracy_dummy = accuracy_score(y_test, pred_dummy)\n",
    "print(f'Accuracy del modelo tonto (baseline) en el conjunto de prueba: {accuracy_dummy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eb74284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo supera claramente al baseline, demostrando que captura patrones útiles y supera la prueba de cordura.\n",
      "Accuracy del mejor modelo (Random Forest) en el conjunto de prueba: 0.795\n"
     ]
    }
   ],
   "source": [
    "# Comparar el mejor modelo con el baseline\n",
    "if accuracy_forest > accuracy_dummy:\n",
    "    print(\"El mejor modelo supera claramente al baseline, demostrando que captura patrones útiles y supera la prueba de cordura.\")\n",
    "    print(f'Accuracy del mejor modelo (Random Forest) en el conjunto de prueba: {accuracy_forest:.3f}')\n",
    "else:\n",
    "    print(\"El mejor modelo no supera al baseline, indicando que no está aprendiendo patrones útiles y falla la prueba de cordura.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea2969e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\models\\\\best_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el mejor modelo\n",
    "dump(best_model, r'..\\models\\best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407a01b",
   "metadata": {},
   "source": [
    "##  Conclusiones\n",
    "\n",
    "En este proyecto se construyeron y compararon tres modelos de clasificación (**Decision Tree**, **Random Forest** y **Logistic Regression**) con el objetivo de predecir si un cliente pertenece a la tarifa *Ultra o *.\n",
    "\n",
    "* El **modelo Dummy (baseline)**, que siempre predice la clase mayoritaria, alcanzó una exactitud del **69.5%** en el conjunto de prueba.\n",
    "* El **mejor modelo encontrado fue Random Forest**, con exactitud del **79.5%** en el conjunto de prueba, superando claramente al baseline y demostrando que captura patrones útiles en los datos.\n",
    "* El modelo no solo mejora la predicción en un **+10% absoluto** frente al baseline, sino que también confirma que los patrones de uso de llamadas, minutos, mensajes y datos móviles son relevantes para distinguir entre clientes *Ultra* y *Smart*.\n",
    "\n",
    "###  Reflexión final\n",
    "\n",
    "* El **árbol de decisión** resultó más simple pero menos preciso, mostrando riesgo de sobreajuste o subajuste según la profundidad con una exactitud del **78.2%**.\n",
    "* La **regresión logística** fue rápida y fácil de interpretar, pero no alcanzó la precisión del bosque con una exactitud del **75.7%**.\n",
    "* El **bosque aleatorio** combinó la robustez de varios árboles y logró el mejor equilibrio entre sesgo y varianza, lo que lo convierte en el modelo más adecuado para este problema con una exactitud del **79.5%**.\n",
    "\n",
    "En conclusión, el **Random Forest Classifier** es el modelo recomendado, ya que supera ampliamente la prueba de cordura y ofrece el mejor rendimiento en el conjunto de prueba, con una exactitud suficiente para ser usado como herramienta predictiva en este escenario.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-classification.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
